{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Equity_1.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Hybrid_1.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Debt_1.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Commodity_1.csv\n",
      "Combined DataFrame 1: Length = 1461\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Equity_2.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Hybrid_2.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Debt_2.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Commodity_2.csv\n",
      "Combined DataFrame 2: Length = 1461\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Equity_3.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Hybrid_3.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Debt_3.csv\n",
      "Processed file: /Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data/MF_Commodity_3.csv\n",
      "Combined DataFrame 3: Length = 1461\n",
      "Combined DataFrame after dropping '_x', '_y' and excluding '%Other%' columns:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "folder_path = '/Users/souravm/Documents/fund_analysis/mutualfund_analysis/Raw_data'\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "# Function to process files based on their identifier (1, 2, 3)\n",
    "def process_files(files, identifier):\n",
    "    dataframes_list = []\n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Add 'Fund Type' based on the file name\n",
    "        if 'Debt' in file:\n",
    "            df['Fund Type'] = 'Debt'\n",
    "        elif 'Equity' in file:\n",
    "            df['Fund Type'] = 'Equity'\n",
    "        elif 'Hybrid' in file:\n",
    "            df['Fund Type'] = 'Hybrid'\n",
    "        elif 'Commodity' in file:\n",
    "            df['Fund Type'] = 'Commodity'\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print(f\"Processed file: {file}\")\n",
    "        dataframes_list.append(df)\n",
    "\n",
    "    # Combine the DataFrames if any were processed\n",
    "    if dataframes_list:\n",
    "        combined_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "        print(f\"Combined DataFrame {identifier}: Length = {len(combined_df)}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(f\"No files with '{identifier}' in the name were found.\")\n",
    "        return None\n",
    "\n",
    "# Filter files with '1', '2', and '3' in the name\n",
    "files_with_one = [file for file in csv_files if '1' in file]\n",
    "files_with_two = [file for file in csv_files if '2' in file]\n",
    "files_with_three = [file for file in csv_files if '3' in file]\n",
    "\n",
    "# Process each set of files\n",
    "df_1 = process_files(files_with_one, '1')\n",
    "df_2 = process_files(files_with_two, '2')\n",
    "df_3 = process_files(files_with_three, '3')\n",
    "\n",
    "# Merge the DataFrames on the common column (assumed to be the first column)\n",
    "if df_1 is not None and df_2 is not None and df_3 is not None:\n",
    "    combined_df = pd.merge(df_1, df_2, on=df_1.columns[0], how='outer')\n",
    "    combined_df = pd.merge(combined_df, df_3, on=combined_df.columns[0], how='outer')\n",
    "\n",
    "    # Step 1: Drop columns with '_x' and '_y' suffixes, but keep the original column\n",
    "    columns_to_drop = [col for col in combined_df.columns if col.endswith('_x') or col.endswith('_y')]\n",
    "    combined_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Step 2: Exclude any columns that contain '%Other%' in their name\n",
    "    columns_to_keep = [col for col in combined_df.columns if 'Other' not in col]\n",
    "    combined_df = combined_df[columns_to_keep]\n",
    "\n",
    "    print(\"Combined DataFrame after dropping '_x', '_y' and excluding '%Other%' columns:\")\n",
    "    # print(combined_df.columns)\n",
    "else:\n",
    "    print(\"One or more DataFrames were empty, skipping the merge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1467 entries, 0 to 1466\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Name                   1467 non-null   object \n",
      " 1   Expense Ratio          1467 non-null   float64\n",
      " 2   Absolute Returns - 3M  1467 non-null   float64\n",
      " 3   Absolute Returns - 6M  1467 non-null   float64\n",
      " 4   Absolute Returns - 1Y  1467 non-null   float64\n",
      " 5   CAGR 3Y                1467 non-null   float64\n",
      " 6   CAGR 5Y                1467 non-null   float64\n",
      " 7   CAGR 10Y               1467 non-null   float64\n",
      " 8   Alpha                  1467 non-null   float64\n",
      " 9   Volatility             1467 non-null   float64\n",
      " 10  Category St Dev        1467 non-null   float64\n",
      " 11  SEBI Risk Category     1467 non-null   object \n",
      " 12  % Debt Holding         1467 non-null   float64\n",
      " 13  % Equity Holding       1467 non-null   float64\n",
      " 14  % Largecap Holding     1467 non-null   float64\n",
      " 15  % Midcap Holding       1467 non-null   float64\n",
      " 16  % Smallcap Holding     1467 non-null   float64\n",
      " 17  PE Ratio               1467 non-null   float64\n",
      " 18  Category PE Ratio      1467 non-null   float64\n",
      " 19  Sharpe Ratio           1467 non-null   float64\n",
      " 20  Sortino Ratio          1467 non-null   float64\n",
      " 21  Sub Category           1467 non-null   object \n",
      " 22  Plan                   1467 non-null   object \n",
      " 23  AUM                    1467 non-null   float64\n",
      " 24  Time since inception   1467 non-null   int64  \n",
      " 25  Benchmark              1467 non-null   object \n",
      " 26  Exit Load              1467 non-null   float64\n",
      " 27  Lock-in                1467 non-null   int64  \n",
      " 28  Minimum Lumpsum        1467 non-null   int64  \n",
      " 29  Minimum SIP            1467 non-null   int64  \n",
      " 30  NAV                    1467 non-null   float64\n",
      " 31  Fund Type              1467 non-null   object \n",
      "dtypes: float64(22), int64(4), object(6)\n",
      "memory usage: 366.9+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
